{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Filtering Methods - Constant, Quasi Constants and Duplicate Feature Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering method\n",
    "\n",
    "Unnecessary and redundant features not only slow down the training time of an algorithm, but they also affect the performance of the algorithm.\n",
    "\n",
    "There are several advantages of performing feature selection before training machine learning models:\n",
    "\n",
    " - Models with less number of features have higher explainability.\n",
    " - It is easier to implement machine learning models with reduced features.\n",
    " - Fewer features lead to enhanced generalization which in turn reduces overfitting.\n",
    " - Feature selection removes data redundancy.\n",
    " - Training time of models with fewer features is significantly lower.\n",
    " - Models with fewer features are less prone to errors.\n",
    "\n",
    "## What is filter method?\n",
    "Features selected using filter methods can be used as an input to any machine learning models.\n",
    "\n",
    " - Univariate -> Fisher Score, Mutual Information Gain, Variance etc\n",
    " - Multi-variate -> Pearson Correlation\n",
    "\n",
    "The univariate filter methods are the type of methods where individual features are ranked according to specific criteria. The top N features are then selected. Different types of ranking criteria are used for univariate filtermethods, for example fisher score, mutual information, and variance of the feature.\n",
    "\n",
    "Multivariate filter methods are capable of removing redundant features from the data since they take the mutual relationship between the features into account.\n",
    "\n",
    "## Univariate Filtering Methods in this lesson\n",
    " - Constant Removal\n",
    " - Quasi Constant Removal\n",
    " - Duplicate Feature Removal\n",
    "\n",
    "Download Data Files https://github.com/laxmimerit/Data-Files-for-Feature-Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# VarianceThreshold - Feature selector that removes all low-variance features.\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/santander.csv\", nrows=20000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"TARGET\", axis=1)  # Features\n",
    "y = data[\"TARGET\"]  # Outcome\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Features Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of features after constants removal\n",
    "constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns True for all the features which are constants.\n",
    "constant_list = [\n",
    "    not temp for temp in constant_filter.get_support()\n",
    "]  # Inversing the True to False and False to True\n",
    "constant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of all the features which are constants\n",
    "x.columns[constant_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the constants from our Training and Test dataset.\n",
    "x_train_filter = constant_filter.transform(x_train)\n",
    "x_test_filter = constant_filter.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take a look at the original and the transformed data (after removing the constants)\n",
    "x_train.shape, x_test.shape, x_train_filter.shape, x_test_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi Constants Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter = VarianceThreshold(threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter.fit(x_train_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_filter.get_support().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_quasi_filter = quasi_constant_filter.transform(x_train_filter)\n",
    "x_test_quasi_filter = quasi_constant_filter.transform(x_test_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take a look at the original and the transformed data (after removing the constants)\n",
    "x_train.shape, x_test.shape, x_train_filter.shape, x_test_filter.shape, x_train_quasi_filter.shape, x_train_quasi_filter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Features Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_T = x_train_quasi_filter.T\n",
    "x_test_T = x_test_quasi_filter.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see the pandas dataframe has been transformed in to numpy array after transpose.\n",
    "type(x_train_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing numpy array back to pandas dataframe\n",
    "x_train_T = pd.DataFrame(x_train_T)\n",
    "x_test_T = pd.DataFrame(x_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see after transpose the rows has become columns and columns has become rows.\n",
    "x_train_T.shape, x_test_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting duplicate features count\n",
    "x_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_features = x_train_T.duplicated()\n",
    "duplicated_features\n",
    "\n",
    "# True is duplicated and False is non duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duppicated features.\n",
    "# After this the False becomes True and True becomes false.\n",
    "\n",
    "# Inversing the True to False and False to True\n",
    "features_to_keep = [not index for index in duplicated_features]\n",
    "features_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset after removing constants, quasi constants and duplicates.\n",
    "\n",
    "# Transposing again to original form\n",
    "x_train_unique = x_train_T[features_to_keep].T\n",
    "\n",
    "# Transposing again to original form\n",
    "x_test_unique = x_test_T[features_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, x_train_unique.shape, x_test_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model and Compare the Performance after and before removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(x_train, x_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(\"Accuracy on test set: \")\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run on final data.\n",
    "run_random_forest(x_train_unique, x_test_unique, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run on original data.\n",
    "run_random_forest(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy and time taken is less after removing the constants, quasi constants and duplicates compare to the original data. \n",
    "\n",
    "What we can say here is that removing constants, quasi constants and duplicates doesn't depricates the accuracy it rather improves it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
